# Image Captioning: PH2P vs BLIP
Authors: Vagdevi Sahasra Bandaru

# How To Run 
## 1. Image Captioning: BLIP Image Captioning Base Model
### Reference Folder: blip-image-caption-base
For executing the code files please refer to the README inside the 'blip-image-caption-base' folder. The README has a clear explanation along with detailed instructions to load necessary data for executing th files.

## 2. Image Captioning: BLIP Image Captioning Large Model
### Reference Folder: blip-image-caption-large
For executing the code files please refer to the README inside the 'blip-image-caption-large' folder. The README has a clear explanation along with detailed instructions to load necessary data for executing th files.

## 3. Image Captioning: BLIP2 Flan-T5-XL Model
### Reference Folder: blip2-flan-t5-xl
For executing the code files please refer to the README inside the 'blip2-flan-t5-xl' folder. The README has a clear explanation along with detailed instructions to load necessary data for executing th files.

# Citations
[1] Mahajan, Shweta, et al. "Prompting Hard or Hardly Prompting: Prompt Inversion for Text-to-Image Diffusion Models." Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2024.

[2] Li, Junnan, et al. "Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation." International conference on machine learning. PMLR, 2022.

[3] Li, Junnan, et al. "Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models." International conference on machine learning. PMLR, 2023.

[4] huggingface. (n.d.). blip-2.md. GitHub. github.com/huggingface/blog/blob/main/blip-2.md
